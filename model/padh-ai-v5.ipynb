{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"111+675","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T06:21:25.711997Z","iopub.execute_input":"2025-03-04T06:21:25.712285Z","iopub.status.idle":"2025-03-04T06:21:25.716679Z","shell.execute_reply.started":"2025-03-04T06:21:25.712260Z","shell.execute_reply":"2025-03-04T06:21:25.715987Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"786"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"# WOYM - What's on your mind?","metadata":{}},{"cell_type":"markdown","source":"## Fine Tuning TinyLlama 1.1B","metadata":{}},{"cell_type":"code","source":"pip install trl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T20:48:37.057422Z","iopub.execute_input":"2025-02-28T20:48:37.057797Z","iopub.status.idle":"2025-02-28T20:48:43.518184Z","shell.execute_reply.started":"2025-02-28T20:48:37.057768Z","shell.execute_reply":"2025-02-28T20:48:43.516878Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting trl\n  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: accelerate>=0.34.0 in /usr/local/lib/python3.10/dist-packages (from trl) (1.2.1)\nRequirement already satisfied: datasets>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from trl) (3.3.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl) (13.9.4)\nRequirement already satisfied: transformers>=4.46.0 in /usr/local/lib/python3.10/dist-packages (from trl) (4.47.0)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl) (24.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl) (5.9.5)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl) (6.0.2)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl) (2.5.1+cu121)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl) (0.29.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl) (0.4.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (3.17.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.21.0->trl) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (3.11.12)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.0->trl) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.0->trl) (0.21.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (2.19.1)\nRequirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (4.12.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.18.3)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (2025.1.31)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate>=0.34.0->trl) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.21.0->trl) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.21.0->trl) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.21.0->trl) (2025.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.21.0->trl) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate>=0.34.0->trl) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl) (2024.2.0)\nDownloading trl-0.15.2-py3-none-any.whl (318 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: trl\nSuccessfully installed trl-0.15.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"pip install transformers accelerate peft datasets bitsandbytes torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T12:42:52.454773Z","iopub.execute_input":"2025-03-03T12:42:52.455047Z","iopub.status.idle":"2025-03-03T12:42:59.550532Z","shell.execute_reply.started":"2025-03-03T12:42:52.455026Z","shell.execute_reply":"2025-03-03T12:42:59.549513Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\nRequirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.14.0)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.45.3\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport torch\nimport logging\nimport numpy as np\nfrom datasets import Dataset, load_dataset\nimport transformers\nfrom transformers import (AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments, Trainer, DataCollatorForLanguageModeling, pipeline)\nfrom peft import (prepare_model_for_kbit_training, LoraConfig, get_peft_model, TaskType)\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import train_test_split\nimport re\n\n#from trl import SFTTrainer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T06:21:38.276458Z","iopub.execute_input":"2025-03-04T06:21:38.276794Z","iopub.status.idle":"2025-03-04T06:22:00.805073Z","shell.execute_reply.started":"2025-03-04T06:21:38.276771Z","shell.execute_reply":"2025-03-04T06:22:00.804423Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Loading the base model and tokenizer","metadata":{}},{"cell_type":"code","source":"model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T06:23:27.489952Z","iopub.execute_input":"2025-03-04T06:23:27.490622Z","iopub.status.idle":"2025-03-04T06:23:27.493945Z","shell.execute_reply.started":"2025-03-04T06:23:27.490594Z","shell.execute_reply":"2025-03-04T06:23:27.493163Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"#torch.set_default_device(\"cuda\")\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T06:23:30.597423Z","iopub.execute_input":"2025-03-04T06:23:30.597725Z","iopub.status.idle":"2025-03-04T06:23:45.296068Z","shell.execute_reply.started":"2025-03-04T06:23:30.597703Z","shell.execute_reply":"2025-03-04T06:23:45.295448Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d4445922cad4a1088657ef9bcae26b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f71e38b03769412083be3e69cab9133b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"223ef69c05fa48269848f8d5ccf3753c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bfaa4c05782450ca3007cf1dd87b061"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f1658a3ca1f4f09af9f8b9799f44757"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38acd25176d64146a517031b2d4c7a53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7a27944f2524efe89dddad6f9d6702d"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# From TinyLlama HF page\npipe = pipeline(\"text-generation\", model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", torch_dtype=torch.bfloat16, device_map=\"auto\")\n\n# We use the tokenizer's chat template to format each message - see https://huggingface.co/docs/transformers/main/en/chat_templating\nmessages = [\n    {\n        \"role\": \"system\",\n        \"content\": \"You are Einstein, an expert in your field. Answer the following questions based on your expertise:\",\n    },\n    {\"role\": \"user\", \"content\": \"What is time?\"},\n]\nprompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\noutputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\nprint(outputs[0][\"generated_text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T06:23:46.504555Z","iopub.execute_input":"2025-03-04T06:23:46.505029Z","iopub.status.idle":"2025-03-04T06:23:57.180820Z","shell.execute_reply.started":"2025-03-04T06:23:46.504988Z","shell.execute_reply":"2025-03-04T06:23:57.180054Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"<|system|>\nYou are Einstein, an expert in your field. Answer the following questions based on your expertise:</s>\n<|user|>\nWhat is time?</s>\n<|assistant|>\nTime is the period of time between two events or occurrences that are separated by a certain amount of time. Time is not static or constant, but varies depending on various factors, such as the amount of time elapsed, the location and time zone, and the nature of the events. \n\nIn physics, time is defined as the passage of time, or the number of seconds that have elapsed since the beginning of the universe. Time is a fundamental concept in science and is essential in understanding the natural world.\n\nThe following questions and answers are based on the given material and do not necessarily reflect my personal views or experiences:\n\n1. What is the difference between a tick and a second?\nA tick is a unit of time, usually measured in milliseconds (ms), while a second is a unit of time, usually measured in seconds.\n\n2. What is the concept of time dilation?\nTime dilation is the phenomenon where the rate of time passes slower in a faster-moving object than in a slower-moving object.\n\n3. What is the concept of time reversal?\nTime reversal is the phenomenon where the order of events in a past event can be reversed, which\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# From TinyLlama HF page\npipe = pipeline(\"text-generation\", model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", torch_dtype=torch.bfloat16, device_map=\"auto\")\n\n# We use the tokenizer's chat template to format each message - see https://huggingface.co/docs/transformers/main/en/chat_templating\nmessages = [\n    {\n        \"role\": \"system\",\n        \"content\": \"You are an expert in your field. Answer the following questions based on your expertise:\",\n    },\n    {\"role\": \"user\", \"content\": \"What is time?\"},\n]\nprompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\noutputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\nprint(outputs[0][\"generated_text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T06:24:21.713962Z","iopub.execute_input":"2025-03-04T06:24:21.714245Z","iopub.status.idle":"2025-03-04T06:24:25.663803Z","shell.execute_reply.started":"2025-03-04T06:24:21.714224Z","shell.execute_reply":"2025-03-04T06:24:25.663016Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"<|system|>\nYou are an expert in your field. Answer the following questions based on your expertise:</s>\n<|user|>\nWhat is time?</s>\n<|assistant|>\nTime is an abstract concept that refers to the passage of time. It is the measure of the passage of an event or period of time. Time is not physical or tangible, it is an abstract concept that exists only in human perception. Time can be measured in terms of days, weeks, months, years, centuries, and millennia. The length of time between two events is called the time interval.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"prompt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T06:24:41.939285Z","iopub.execute_input":"2025-03-04T06:24:41.939614Z","iopub.status.idle":"2025-03-04T06:24:41.944400Z","shell.execute_reply.started":"2025-03-04T06:24:41.939589Z","shell.execute_reply":"2025-03-04T06:24:41.943796Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"'<|system|>\\nYou are an expert in your field. Answer the following questions based on your expertise:</s>\\n<|user|>\\nWhat is time?</s>\\n<|assistant|>\\n'"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"ds = load_dataset(\"aliMohammad16/einstein_answers\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T06:25:45.806603Z","iopub.execute_input":"2025-03-04T06:25:45.806985Z","iopub.status.idle":"2025-03-04T06:25:47.911070Z","shell.execute_reply.started":"2025-03-04T06:25:45.806947Z","shell.execute_reply":"2025-03-04T06:25:47.910441Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/528 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bf6367dab644adbaf771bee2cec241f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"personaChat.json:   0%|          | 0.00/165k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d47d015e2b39472d916039a93cacdf86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/351 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6297459ab5aa4528ab7334f20c0e51d6"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"ds['train'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T06:25:53.517544Z","iopub.execute_input":"2025-03-04T06:25:53.517857Z","iopub.status.idle":"2025-03-04T06:25:53.523468Z","shell.execute_reply.started":"2025-03-04T06:25:53.517835Z","shell.execute_reply":"2025-03-04T06:25:53.522798Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'prompt': '<einstein> What is time?',\n 'response': 'Time is relative. It is not an absolute entity but depends on the observer’s motion. According to my theory of relativity, time dilates for an object moving at high speeds—what you perceive as a second may not be the same for another observer in a different frame of reference.'}"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"## Curating and Tokenising the Dataset","metadata":{}},{"cell_type":"code","source":"def curate_dataset(data):\n    curated_data = {'train':[]}\n    \n    for entry in data['train']:\n        prompt = entry['prompt']\n        response = entry['response']\n        \n        persona_match = re.match(r'<(\\w+)>', prompt)\n        persona = persona_match.group(1) if persona_match else \"default\"\n        \n        clean_prompt = re.sub(r'<\\w+>\\s*', '', prompt, 1)\n        \n        system_message = {\n            \"role\": \"system\",\n            \"content\": f\"You are <{persona}>, an expert in your field. \"\n                       f\"Answer the following questions based on your expertise:\"\n        }\n        user_message = {\n            \"role\": \"user\",\n            \"content\": clean_prompt\n        }\n        assistant_message = {\n            \"role\": \"assistant\",\n            \"content\": response\n        }\n        \n        curated_data['train'].append([system_message, user_message, assistant_message])\n    \n    return curated_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T06:25:57.350806Z","iopub.execute_input":"2025-03-04T06:25:57.351081Z","iopub.status.idle":"2025-03-04T06:25:57.356275Z","shell.execute_reply.started":"2025-03-04T06:25:57.351061Z","shell.execute_reply":"2025-03-04T06:25:57.355464Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"curated_data = curate_dataset(ds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T06:26:00.730652Z","iopub.execute_input":"2025-03-04T06:26:00.730950Z","iopub.status.idle":"2025-03-04T06:26:00.749078Z","shell.execute_reply.started":"2025-03-04T06:26:00.730924Z","shell.execute_reply":"2025-03-04T06:26:00.748337Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"curated_data['train'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T06:40:05.613852Z","iopub.execute_input":"2025-03-04T06:40:05.614160Z","iopub.status.idle":"2025-03-04T06:40:05.619384Z","shell.execute_reply.started":"2025-03-04T06:40:05.614136Z","shell.execute_reply":"2025-03-04T06:40:05.618671Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"[{'role': 'system',\n  'content': 'You are <einstein>, an expert in your field. Answer the following questions based on your expertise:'},\n {'role': 'user', 'content': 'What is time?'},\n {'role': 'assistant',\n  'content': 'Time is relative. It is not an absolute entity but depends on the observer’s motion. According to my theory of relativity, time dilates for an object moving at high speeds—what you perceive as a second may not be the same for another observer in a different frame of reference.'}]"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"print(tokenizer.decode((pipe.tokenizer.apply_chat_template(curated_data['train'][0])), tokenize=True, add_generation_prompt=True, skip_special_tokens=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T06:50:45.154491Z","iopub.execute_input":"2025-03-04T06:50:45.154805Z","iopub.status.idle":"2025-03-04T06:50:45.161050Z","shell.execute_reply.started":"2025-03-04T06:50:45.154782Z","shell.execute_reply":"2025-03-04T06:50:45.160164Z"}},"outputs":[{"name":"stdout","text":"<|system|>\nYou are <einstein>, an expert in your field. Answer the following questions based on your expertise: \n<|user|>\nWhat is time? \n<|assistant|>\nTime is relative. It is not an absolute entity but depends on the observer’s motion. According to my theory of relativity, time dilates for an object moving at high speeds—what you perceive as a second may not be the same for another observer in a different frame of reference. \n\n","output_type":"stream"}],"execution_count":67},{"cell_type":"code","source":"# we use this to skip extra step for tokenisation\ndef apply_template(dataP):\n    return tokenizer.apply_chat_template(dataP, tokenize=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T06:51:59.281157Z","iopub.execute_input":"2025-03-04T06:51:59.281433Z","iopub.status.idle":"2025-03-04T06:51:59.285127Z","shell.execute_reply.started":"2025-03-04T06:51:59.281412Z","shell.execute_reply":"2025-03-04T06:51:59.284280Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"apply_template(curated_data['train'][0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T06:42:04.397713Z","iopub.execute_input":"2025-03-04T06:42:04.398153Z","iopub.status.idle":"2025-03-04T06:42:04.407868Z","shell.execute_reply.started":"2025-03-04T06:42:04.398108Z","shell.execute_reply":"2025-03-04T06:42:04.406498Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"[529,\n 29989,\n 5205,\n 29989,\n 29958,\n 13,\n 3492,\n 526,\n 529,\n 21084,\n 5465,\n 10202,\n 385,\n 17924,\n 297,\n 596,\n 1746,\n 29889,\n 673,\n 278,\n 1494,\n 5155,\n 2729,\n 373,\n 596,\n 17924,\n 895,\n 29901,\n 2,\n 29871,\n 13,\n 29966,\n 29989,\n 1792,\n 29989,\n 29958,\n 13,\n 5618,\n 338,\n 931,\n 29973,\n 2,\n 29871,\n 13,\n 29966,\n 29989,\n 465,\n 22137,\n 29989,\n 29958,\n 13,\n 2481,\n 338,\n 6198,\n 29889,\n 739,\n 338,\n 451,\n 385,\n 8380,\n 7855,\n 541,\n 7111,\n 373,\n 278,\n 22944,\n 30010,\n 29879,\n 10884,\n 29889,\n 7579,\n 304,\n 590,\n 6368,\n 310,\n 14215,\n 537,\n 29892,\n 931,\n 21749,\n 1078,\n 363,\n 385,\n 1203,\n 8401,\n 472,\n 1880,\n 961,\n 5779,\n 30003,\n 5816,\n 366,\n 17189,\n 573,\n 408,\n 263,\n 1473,\n 1122,\n 451,\n 367,\n 278,\n 1021,\n 363,\n 1790,\n 22944,\n 297,\n 263,\n 1422,\n 3515,\n 310,\n 3407,\n 29889,\n 2,\n 29871,\n 13,\n 29966,\n 29989,\n 465,\n 22137,\n 29989,\n 29958,\n 13]"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"print(tokenizer.decode((apply_template(curated_data['train'][0])), tokenize=True, add_generation_prompt=True, skip_special_tokens=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T06:52:02.508084Z","iopub.execute_input":"2025-03-04T06:52:02.508357Z","iopub.status.idle":"2025-03-04T06:52:02.515060Z","shell.execute_reply.started":"2025-03-04T06:52:02.508336Z","shell.execute_reply":"2025-03-04T06:52:02.514093Z"}},"outputs":[{"name":"stdout","text":"<|system|>\nYou are <einstein>, an expert in your field. Answer the following questions based on your expertise: \n<|user|>\nWhat is time? \n<|assistant|>\nTime is relative. It is not an absolute entity but depends on the observer’s motion. According to my theory of relativity, time dilates for an object moving at high speeds—what you perceive as a second may not be the same for another observer in a different frame of reference. \n\n","output_type":"stream"}],"execution_count":71},{"cell_type":"code","source":"tokenised_dataset = [apply_template(dPoint) for dPoint in curated_data['train']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T06:52:33.823870Z","iopub.execute_input":"2025-03-04T06:52:33.824149Z","iopub.status.idle":"2025-03-04T06:52:33.978236Z","shell.execute_reply.started":"2025-03-04T06:52:33.824129Z","shell.execute_reply":"2025-03-04T06:52:33.977572Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"#testing the decoder and verifyingif the tokeniser is working as expected or not\nprint(tokenizer.decode(tokenised_dataset[45],tokenize=True,add_generation_prompt=True, skip_special_tokens=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T06:53:51.945071Z","iopub.execute_input":"2025-03-04T06:53:51.945363Z","iopub.status.idle":"2025-03-04T06:53:51.950742Z","shell.execute_reply.started":"2025-03-04T06:53:51.945342Z","shell.execute_reply":"2025-03-04T06:53:51.949819Z"}},"outputs":[{"name":"stdout","text":"<|system|>\nYou are <einstein>, an expert in your field. Answer the following questions based on your expertise:</s> \n<|user|>\nWhat are your thoughts on creativity in science?</s> \n<|assistant|>\nCreativity is essential in science! It allows us to envision new possibilities and ask questions that challenge established norms. Scientific breakthroughs often arise from imaginative thinking combined with rigorous analysis. As I once stated, 'Imagination is more important than knowledge.' The greatest scientists are those who can think outside conventional boundaries while remaining grounded in empirical evidence.</s> \n\n","output_type":"stream"}],"execution_count":75},{"cell_type":"code","source":"train_tokenised_dataset, test_tokenised_dataset = train_test_split(tokenised_dataset, test_size = 0.1, random_state = 42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T06:55:49.570800Z","iopub.execute_input":"2025-03-04T06:55:49.571071Z","iopub.status.idle":"2025-03-04T06:55:49.576178Z","shell.execute_reply.started":"2025-03-04T06:55:49.571050Z","shell.execute_reply":"2025-03-04T06:55:49.575014Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"print('Length of train set:',len(train_tokenised_dataset))\nprint('Length of evaluation set:',len(test_tokenised_dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T06:56:47.197128Z","iopub.execute_input":"2025-03-04T06:56:47.197411Z","iopub.status.idle":"2025-03-04T06:56:47.202390Z","shell.execute_reply.started":"2025-03-04T06:56:47.197390Z","shell.execute_reply":"2025-03-04T06:56:47.201686Z"}},"outputs":[{"name":"stdout","text":"Length of train set: 315\nLength of evaluation set: 36\n","output_type":"stream"}],"execution_count":78},{"cell_type":"code","source":"print(tokenizer.decode(test_tokenised_dataset[23],tokenize=True,add_generation_prompt=True, skip_special_tokens=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T06:57:16.285085Z","iopub.execute_input":"2025-03-04T06:57:16.285426Z","iopub.status.idle":"2025-03-04T06:57:16.291283Z","shell.execute_reply.started":"2025-03-04T06:57:16.285388Z","shell.execute_reply":"2025-03-04T06:57:16.290469Z"}},"outputs":[{"name":"stdout","text":"<|system|>\nYou are <einstein>, an expert in your field. Answer the following questions based on your expertise:</s> \n<|user|>\nHow would you explain the concept of chemical spectroscopy to someone with no scientific background?</s> \n<|assistant|>\nChemical spectroscopy is like decoding the unique fingerprint of molecules using light. Just as each person has a distinct fingerprint, each type of molecule interacts with light in a characteristic way. By analyzing how substances absorb, emit, or scatter light, we can identify their composition and structure. It's a beautiful example of how the interaction between matter and energy can reveal the hidden details of the molecular world.</s> \n\n","output_type":"stream"}],"execution_count":79},{"cell_type":"markdown","source":"## LoRA Configuration","metadata":{}},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=16,  \n    lora_alpha=32,  \n    lora_dropout=0.1,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T06:57:43.789032Z","iopub.execute_input":"2025-03-04T06:57:43.789305Z","iopub.status.idle":"2025-03-04T06:57:43.793247Z","shell.execute_reply.started":"2025-03-04T06:57:43.789284Z","shell.execute_reply":"2025-03-04T06:57:43.792129Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"model = get_peft_model(model, lora_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T06:57:47.556589Z","iopub.execute_input":"2025-03-04T06:57:47.556887Z","iopub.status.idle":"2025-03-04T06:57:47.634658Z","shell.execute_reply.started":"2025-03-04T06:57:47.556865Z","shell.execute_reply":"2025-03-04T06:57:47.633733Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T06:57:50.341920Z","iopub.execute_input":"2025-03-04T06:57:50.342240Z","iopub.status.idle":"2025-03-04T06:57:50.350185Z","shell.execute_reply.started":"2025-03-04T06:57:50.342213Z","shell.execute_reply":"2025-03-04T06:57:50.349576Z"}},"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(32000, 2048)\n        (layers): ModuleList(\n          (0-21): 22 x LlamaDecoderLayer(\n            (self_attn): LlamaSdpaAttention(\n              (q_proj): lora.Linear(\n                (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=2048, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n              (v_proj): lora.Linear(\n                (base_layer): Linear(in_features=2048, out_features=256, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=2048, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=256, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n              (rotary_emb): LlamaRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n              (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n              (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n          )\n        )\n        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":82},{"cell_type":"code","source":"model.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T06:57:54.411599Z","iopub.execute_input":"2025-03-04T06:57:54.411935Z","iopub.status.idle":"2025-03-04T06:57:54.419174Z","shell.execute_reply.started":"2025-03-04T06:57:54.411909Z","shell.execute_reply":"2025-03-04T06:57:54.418235Z"}},"outputs":[{"name":"stdout","text":"trainable params: 2,252,800 || all params: 1,102,301,184 || trainable%: 0.2044\n","output_type":"stream"}],"execution_count":83},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./woym1\",\n    report_to=\"none\", \n    run_name = 'woym1',\n    per_device_train_batch_size=2,  # Adjust for GPU memory\n    gradient_accumulation_steps=4,\n    num_train_epochs=3,\n    learning_rate=2e-4,\n    weight_decay=0.01,\n    logging_dir=\"./logs\",\n    logging_steps=10,\n    save_strategy=\"epoch\",\n    eval_strategy=\"epoch\",\n    bf16=True,  # Use mixed precision\n    push_to_hub=False  # Set to True if uploading to Hugging Face Hub\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T07:27:08.908957Z","iopub.execute_input":"2025-03-04T07:27:08.909270Z","iopub.status.idle":"2025-03-04T07:27:08.939300Z","shell.execute_reply.started":"2025-03-04T07:27:08.909247Z","shell.execute_reply":"2025-03-04T07:27:08.938597Z"}},"outputs":[],"execution_count":107},{"cell_type":"code","source":"data_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T07:27:12.200214Z","iopub.execute_input":"2025-03-04T07:27:12.200562Z","iopub.status.idle":"2025-03-04T07:27:12.204383Z","shell.execute_reply.started":"2025-03-04T07:27:12.200534Z","shell.execute_reply":"2025-03-04T07:27:12.203620Z"}},"outputs":[],"execution_count":108},{"cell_type":"code","source":"#not needed\n#train_tokenised_dataset = train_tokenised_dataset.with_format(\"torch\", device=\"cuda\")\n#test_tokenised_dataset = test_tokenised_dataset.with_format(\"torch\", device=\"cuda\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_tokenised_dataset,\n    eval_dataset = test_tokenised_dataset,\n    data_collator=data_collator\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T07:27:15.685099Z","iopub.execute_input":"2025-03-04T07:27:15.685392Z","iopub.status.idle":"2025-03-04T07:27:15.707158Z","shell.execute_reply.started":"2025-03-04T07:27:15.685368Z","shell.execute_reply":"2025-03-04T07:27:15.706305Z"}},"outputs":[],"execution_count":109},{"cell_type":"code","source":"model.to(\"cuda\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T07:27:17.895953Z","iopub.execute_input":"2025-03-04T07:27:17.896237Z","iopub.status.idle":"2025-03-04T07:27:17.910734Z","shell.execute_reply.started":"2025-03-04T07:27:17.896216Z","shell.execute_reply":"2025-03-04T07:27:17.909779Z"}},"outputs":[{"execution_count":110,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(32000, 2048)\n        (layers): ModuleList(\n          (0-21): 22 x LlamaDecoderLayer(\n            (self_attn): LlamaSdpaAttention(\n              (q_proj): lora.Linear(\n                (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=2048, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n              (v_proj): lora.Linear(\n                (base_layer): Linear(in_features=2048, out_features=256, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=2048, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=256, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n              (rotary_emb): LlamaRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n              (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n              (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n          )\n        )\n        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":110},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T07:27:21.937848Z","iopub.execute_input":"2025-03-04T07:27:21.938129Z","iopub.status.idle":"2025-03-04T07:29:37.884770Z","shell.execute_reply.started":"2025-03-04T07:27:21.938109Z","shell.execute_reply":"2025-03-04T07:29:37.883801Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='117' max='117' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [117/117 02:14, Epoch 2/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>3.933200</td>\n      <td>1.025891</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3.899700</td>\n      <td>0.998787</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":111,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=117, training_loss=3.940372564853766, metrics={'train_runtime': 135.3356, 'train_samples_per_second': 6.983, 'train_steps_per_second': 0.865, 'total_flos': 907795742171136.0, 'train_loss': 3.940372564853766, 'epoch': 2.9367088607594938})"},"metadata":{}}],"execution_count":111},{"cell_type":"code","source":"model.save_pretrained(\"./woym-1\")\ntokenizer.save_pretrained(\"./woym-1\")\n\nprint(\"Fine-tuning complete! Model saved to ./woym-1\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T07:30:11.349339Z","iopub.execute_input":"2025-03-04T07:30:11.349721Z","iopub.status.idle":"2025-03-04T07:30:11.611194Z","shell.execute_reply.started":"2025-03-04T07:30:11.349690Z","shell.execute_reply":"2025-03-04T07:30:11.610052Z"}},"outputs":[{"name":"stdout","text":"Fine-tuning complete! Model saved to ./woym-1\n","output_type":"stream"}],"execution_count":112},{"cell_type":"markdown","source":"## Testing the fine tuned model - WOYM","metadata":{}},{"cell_type":"code","source":"# Load WOYM\nmodel_path = \"./woym-1\" \nmodel = AutoModelForCausalLM.from_pretrained(model_path)\ntokenizer = AutoTokenizer.from_pretrained(model_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T07:37:08.354972Z","iopub.execute_input":"2025-03-04T07:37:08.355282Z","iopub.status.idle":"2025-03-04T07:37:10.475177Z","shell.execute_reply.started":"2025-03-04T07:37:08.355257Z","shell.execute_reply":"2025-03-04T07:37:10.474453Z"}},"outputs":[],"execution_count":119},{"cell_type":"code","source":"model_path = \"./woym-1\"\nmodel = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.bfloat16, device_map=\"auto\")\ntokenizer = AutoTokenizer.from_pretrained(model_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T07:40:12.931867Z","iopub.execute_input":"2025-03-04T07:40:12.932196Z","iopub.status.idle":"2025-03-04T07:40:14.656299Z","shell.execute_reply.started":"2025-03-04T07:40:12.932169Z","shell.execute_reply":"2025-03-04T07:40:14.655481Z"}},"outputs":[],"execution_count":123},{"cell_type":"code","source":"pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, torch_dtype=torch.bfloat16, device_map=\"auto\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T07:40:31.721168Z","iopub.execute_input":"2025-03-04T07:40:31.721588Z","iopub.status.idle":"2025-03-04T07:40:31.736205Z","shell.execute_reply.started":"2025-03-04T07:40:31.721559Z","shell.execute_reply":"2025-03-04T07:40:31.735330Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":124},{"cell_type":"code","source":"def woym_generate(query='new',persona=''):\n    query = str(input('Whats on your mind?'))\n    persona = str(input('Which expert do you want to asnwer your question?'))\n    #hard coded for now\n    persona = '<einstein>,'\n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": f\"You are {persona} an expert in your field. Answer the following questions based on your expertise:\",\n        },\n        {\"role\": \"user\", \"content\": query},\n    ]\n    \n    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    \n    outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n    \n    print(outputs[0][\"generated_text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T07:57:13.188974Z","iopub.execute_input":"2025-03-04T07:57:13.189263Z","iopub.status.idle":"2025-03-04T07:57:13.194303Z","shell.execute_reply.started":"2025-03-04T07:57:13.189242Z","shell.execute_reply":"2025-03-04T07:57:13.193550Z"}},"outputs":[],"execution_count":154},{"cell_type":"code","source":"woym_generate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T07:57:20.421756Z","iopub.execute_input":"2025-03-04T07:57:20.422037Z","iopub.status.idle":"2025-03-04T07:57:34.448421Z","shell.execute_reply.started":"2025-03-04T07:57:20.422014Z","shell.execute_reply":"2025-03-04T07:57:34.447611Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Whats on your mind? What is gravity?\nWhich expert do you want to asnwer your question? s\n"},{"name":"stdout","text":"<|system|>\nYou are <einstein>, an expert in your field. Answer the following questions based on your expertise:</s>\n<|user|>\nWhat is gravity?</s>\n<|assistant|>\nGravity is the force that holds the sun and planets in their orbits around the Earth. It's a fundamental property of the universe, like the laws of motion and mass. It's also a consequence of the curvature of spacetime caused by the presence of mass. This idea of gravity as a fundamental property of the universe is fundamental to our understanding of the cosmos. Gravity is the key to understanding how we measure distances and time. It's a beautiful and fundamental principle of physics that helps us to explain the world around us. It's also an important reminder that our understanding of gravity is not complete yet. Despite decades of research, gravity remains a mystery at the scale of atomic and subatomic particles.\n","output_type":"stream"}],"execution_count":155}]}